<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LRRU: Long-short Range Recurrent Updating Networks for Depth Completion</title>
  <!-- Bootstrap -->
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2>LRRU: Long-short Range Recurrent Updating Networks for Depth Completion</h2>
          <h4 style="color:#5a6268;">International Conference on Computer Vision (ICCV), 2023.</h4>
          <hr>
          <h6>
            <a href="https://scholar.google.com/citations?user=kDaztnkAAAAJ&hl=en" target="_blank">Yufei Wang</a><sup>1</sup>,
            <a  target="_blank">Bo Li</a><sup>1</sup>,
            <a  target="_blank">Ge Zhange</a><sup>1</sup>,
            <a  target="_blank">Qi Liu</a><sup>1</sup>,
            <a  target="_blank">Tao Gao</a><sup>2</sup>,
            <a href="https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl=en" target="_blank">Yuchao Dai</a><sup>1</sup>
          </h6>
          <p><sup>1</sup> Northwestern Polytechnical University and Shaanxi Key Laboratory of
Information Acquisition and Processing &nbsp;&nbsp;
<br>
            <sup>2</sup>Chang'an University
           <!--  <br>
            <sup>2</sup> Corresponding authors -->
          </p>


          <div class="row justify-content-center">
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2310.08956" role="button"
                  target="_blank">
                  <i class="fa fa-file"></i> Arxiv </a> </p>
            </div>
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/YufeiWang777/LRRU" role="button" target="_blank">
                  <i class="fa fa-github-alt"></i> Code </a> </p>
            </div>
            <!-- <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://xxx" role="button">
                  <i class="fa fa-file"></i> Supplementary </a> </p>
            </div> -->
            <!-- <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button">
                  <i class="fa fa-database"></i> Data</a> </p>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Performance -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
          <!-- <h3></h3> -->
          <hr style="margin-top:0px">
          <p>
            <!-- <a href="https://paperswithcode.com/sota/monocular-depth-estimation-on-kitti-eigen?p=new-crfs-neural-window-fully-connected-crfs-1">
              Results on KITTI eigen:
            </a> -->

<!--               <a href="https://paperswithcode.com/sota/monocular-depth-estimation-on-kitti-eigen?p=new-crfs-neural-window-fully-connected-crfs-1">
              <img class="img-fluid" src="./NeW CRFs_ Neural Window Fully-connected CRFs for Monocular Depth Estimation_files/endpoint.svg" alt="NeW CRFs">
            </a> 
          </p>
          <p>
            <a href="https://paperswithcode.com/sota/monocular-depth-estimation-on-nyu-depth-v2?p=new-crfs-neural-window-fully-connected-crfs-1">
              <img class="img-fluid" src="./NeW CRFs_ Neural Window Fully-connected CRFs for Monocular Depth Estimation_files/endpoint(1).svg" alt="NeW CRFs">
            </a> 
          </p>
          <p> -->

            <a href="http://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_completion">
              Rank 1st on the KITTI depth online benchmark from 29-10-2022 to 27-09-2023:
            </a>
            <a href="http://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_completion">
              <img class="img-fluid" src="images/LRRU_on_KITTI.png" alt="KITTI learder board" ,="" width="90%">
            </a> 
          </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- showcase -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <!-- <h3>Poster </h3> -->
        <hr style="margin-top:0px">
        <img class="img-fluid" width="100%" src="images/07190_poster.png" alt="Architecture">

        <p></p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- abstract -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Abstract</h3>
        <hr style="margin-top:0px">
        <p class="text-left">
        Existing deep learning-based depth completion methods generally employ massive stacked layers to predict the dense depth map from sparse input data. Although such approaches greatly advance this task, their accompanied huge computational complexity hinders their practical applications. To accomplish depth completion more efficiently, we propose a novel lightweight deep network framework, the Long-short Range Recurrent Updating (LRRU) network. Without learning complex feature representations, LRRU first roughly fills the sparse input to obtain an initial dense depth map, and then iteratively updates it through learned spatially-variant kernels. Our iterative update process is content-adaptive and highly flexible, where the kernel weights are learned by jointly considering the guidance RGB images and the depth map to be updated, and large-to-small kernel scopes are dynamically adjusted to capture long-to-short range dependencies. Our initial depth map has coarse but complete scene depth information, which helps relieve the burden of directly regressing the dense depth from sparse ones, while our proposed method can effectively refine it to an accurate depth map with less learnable parameters and inference time. Experimental results demonstrate that our proposed LRRU variants achieve state-of-the-art performance across different parameter regimes. In particular, the LRRU-Base model outperforms competing approaches on the NYUv2 dataset, and ranks 1st on the KITTI depth completion benchmark at the time of submission.
         </p>
      </div>
    </div>
  </div>
</section>
<br>


<!-- overview video -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Video</h3>
        <hr style="margin-top:0px">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe width="950" height="534" src="https://www.youtube.com/embed/KBU0asJ8J2Y" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>
<br>


<!-- ablation study -->
<!-- <section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Ablation studies</h3>
        <hr style="margin-top:0px">
        <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
          <source src="https://www.youtube.com/xxxxx" type="video/mp4">
        </video>
        <img class="img-fluid" width="95%" src="images/xxx.png" alt="ablation study">
      </div>
    </div>
  </div>
</section>
<br> -->

<!-- comparison -->
<!-- <section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Comparison with state-of-the-art methods</h3>
        <hr style="margin-top:0px">
        <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
          <source src="./videos/xxx.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>
<br> -->

<!-- citing -->
<div class="container">
  <div class="row ">
    <div class="col-12">
      <h3>Citation</h3>
      <hr style="margin-top:0px">
      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@InProceedings{LRRU_ICCV_2023,
  author    = {Wang, Yufei and Li, Bo and Zhang, Ge and Liu, Qi and Gao Tao and Dai, Yuchao},
  title     = {LRRU: Long-short Range Recurrent Updating Networks for Depth Completion},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2023},
}
</code></pre>
      <hr>
    </div>
  </div>
</div>

<footer class="text-center" style="margin-bottom:10px">
  <br>
  Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
</footer>

</body>

</html>
