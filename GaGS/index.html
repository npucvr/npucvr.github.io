<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>3D Geometry-aware Deformable Gaussian Splatting for Dynamic View Synthesis</title>
  <!-- Bootstrap -->
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <!-- <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script> -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
</head>

<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2>3D Geometry-aware Deformable Gaussian Splatting for Dynamic View Synthesis
          <!-- <h4 style="color:#5a6268;">On submission</h4> -->
          <h4 style="color:#5a6268;">CVPR 2024</h4>
          <hr>
          <h6>
            <a href="" target="_blank">Zhicheng Lu</a><sup>1</sup>,
            <a href="" target="_blank">Xiang Guo</a><sup>1</sup>,
            <a href="" target="_blank">Le Hui</a><sup>1</sup>,
            <a href="" target="_blank">Tianrui Chen</a><sup>1,2</sup>,
            <a href="" target="_blank">Min Yang</a><sup>2</sup>,
            <a href="" target="_blank">Xiao Tang</a><sup>2</sup>,
            <a href="" target="_blank">Feng Zhu</a><sup>2</sup>,
            <a href="" target="_blank">Yuchao Dai</a><sup>1</sup>
          </h6>
          <p><sup>1</sup>School of Electronics and Information, Northwestern Polytechnical University &nbsp;&nbsp;
            <sup>2</sup>Samsung R&D Institute
          </p>

          <div class="row justify-content-center">
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2404.06270" role="button" target="_blank">
                  <i class="fa fa-file"></i> arXiv </a> </p>
            </div>
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/zhichengLuxx/GaGS" role="button" target="">
                  <i class="fa fa-github-alt"></i> Code  </a> </p>
            </div>
            <!-- <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://xxx" role="button">
                  <i class="fa fa-file"></i> Supplementary </a> </p>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- abstract -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Abstract</h3>
        <hr style="margin-top:0px">
        <p class="text-left">In this paper, we propose a 3D geometry-aware deformable Gaussian Splatting method for dynamic view synthesis. Existing neural radiance fields (NeRF) based solutions learn the deformation in an implicit manner, which cannot incorporate 3D scene geometry. Therefore, the learned deformation is not necessarily geometrically coherent, which results in unsatisfactory dynamic view synthesis and 3D dynamic reconstruction. Recently, 3D Gaussian Splatting provides a new representation of the 3D scene, building upon which the 3D geometry could be exploited in learning the complex 3D deformation. Specifically, the scenes are represented as a collection of 3D Gaussian, where each 3D Gaussian is optimized to move and rotate over time to model the deformation. To enforce the 3D scene geometry constraint during deformation, we explicitly extract 3D geometry features and integrate them in learning the 3D deformation. In this way, our solution achieves 3D geometry-aware deformation modeling, which enables improved dynamic view synthesis and 3D dynamic reconstruction. Extensive experimental results on both synthetic and real datasets prove the superiority of our solution, which achieves new state-of-the-art performance. </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- overview video
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Overview video</h3>
        <hr style="margin-top:0px">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe width="950" height="534" src="https://www.youtube.com/embed/0p7uUSMkahw" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>
<br> -->

<!-- showcase -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Our Architecture</h3>
        <hr style="margin-top:0px">
          <img class="img-fluid" width="95%" src="images/structure.png" alt="Architecture">
        <p class="text-left"> The pipeline of our proposed 3D geometry-aware deformable Gaussian splitting. In the Gaussian canonical field, we reconstruct a static scene in canonical space using 3D Gaussian distributions. We extract positional features using a MLP, as well as local geometric features using a 3D U-Net, fused by another MLP to form the geometry-aware features. In the deformation field, taking the geometry-aware features and timestamp t, a MLP estimates the 3D Gaussian deformation, which transfers the canonical 3D Gaussian distributions to timestamp $t$. Finally, a rasterizer renders the transformed 3D Gaussian to images.</p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- Qualitative comparison-->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Qualitative comparison</h3>
        <hr style="margin-top:0px">
        <img class="img-fluid" width="95%" src="images/comparison1.png" alt="Qualitative comparison">
        <p class="text-center"> 
          Qualitative comparisons between baselines and our method on the synthetic dataset.
        </p>
        <img class="img-fluid" width="95%" src="images/comparison2.png" alt="Qualitative comparison">
        <p class="text-center"> 
          Quantitative comparison between our method and competing methods on the D-NeRF dataset. The best results are highlighted in bold.
        </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- More visualization -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Visualization on more dataset</h3>
        <hr style="margin-top:0px">
        <img class="img-fluid" width="95%" src="images/viz.png" alt="flow uncertainty visualization">
        <p class="text-center"> 
          Rendered images with varying timestamps.
        </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- More visualization
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>IoU per-frame over time</h3>
        <hr style="margin-top:0px">
        <img class="img-fluid" width="95%" src="images/iou_with_time.png" alt="IoU per-frame over time">
        <p class="text-left"> 
        IoU per-frame over time of Ours, STM and AFB-URR on five video sequences from DAVIS17 validation set. The last three columns have multiple objects, while the first two columns have only a single object. Since we effectively use the motion information between adjacent frames, the IoU can remain high even in the latter part of the video sequences.
        </p>
      </div>
    </div>
  </div>
</section>
<br> -->

<!-- citing -->
<div class="container">
  <div class="row ">
    <div class="col-12">
      <h3>Citation</h3>
      <hr style="margin-top:0px">
      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{lu2024gagaussian,
  title={3D Geometry-aware Deformable Gaussian Splatting for Dynamic View Synthesis},
  author={Lu, Zhicheng and Guo, Xiang and Hui, Le and Chen, Tianrui and Yang, Ming and Tang, Xiao and Zhu, Feng and Dai, Yuchao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

</code></pre>
      <hr>
    </div>
  </div>
</div>

<footer class="text-center" style="margin-bottom:10px">
  <br>
  Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
</footer>

</body>

</html>
